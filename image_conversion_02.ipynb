{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASCII Art from an Image (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task Queue\n",
    "Learn more about task queues here: [Celery Intro](http://docs.celeryproject.org/en/latest/getting-started/introduction.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Celery is a task queue -> distributes work across threads or machines\n",
    "* Celery communicates via messages, usually using a broker\n",
    "\n",
    "## Here's a \"simple\" diagram of how Celery works:\n",
    "![](./celery_architecture.jpg)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this case\n",
    "- This Notebook is a **Client**. \n",
    "- RabbitMQ is the **Message transport/broker**\n",
    "- We'll set up the **Workers** below\n",
    "- RabbitMQ will store the **backend results** for now, but we'll extend this to DynamoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Broker\n",
    "Learn more about tasks queues with RabbitMQ: [First Steps with Celery](http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html#rabbitmq)\n",
    "\n",
    "Then follow these docs to set up a user: [Using RabbitMQ with Celery](http://docs.celeryproject.org/en/latest/getting-started/brokers/rabbitmq.html)\n",
    "\n",
    "#### I save my RabbitMQ config in the environment I'm working on.\n",
    "This prevents accidentally pushing some private keys to the cloud and allows me to have separate settings for each project.\n",
    "\n",
    "* export CELERY_BROKER_USERNAME='username'\n",
    "* export CELERY_BROKER_PASSWORD='password'\n",
    "* export CELERY_BROKER_SERVER='localhost'\n",
    "* export CELERY_BROKER_PORT='5672'\n",
    "* export CELERY_BROKER_VHOST='host'\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Celery worker\n",
    "Create a celery worker called celery.py in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from celery import Celery\n",
    "\n",
    "\n",
    "CELERY_MAIN = 'tasks'\n",
    "BROKER_DETAILS = dict(user=os.environ.get('CELERY_BROKER_USERNAME'),\n",
    "                          password=os.environ.get('CELERY_BROKER_PASSWORD'),\n",
    "                          server=os.environ.get('CELERY_BROKER_SERVER'),\n",
    "                          port=os.environ.get('CELERY_BROKER_PORT'),\n",
    "                          vhost=os.environ.get('CELERY_BROKER_VHOST'))\n",
    "CELERY_BROKER_URL = 'amqp://{user}:{password}@{server}:{port}/{vhost}'.format(**BROKER_DETAILS)\n",
    "\n",
    "CELERY_CONFIG = dict(\n",
    "    CELERY_RESULT_BACKEND = 'amqp://{user}:{password}@{server}:{port}/{vhost}'.format(**BROKER_DETAILS),\n",
    "    CELERY_TASK_SERIALIZER = 'json',\n",
    "    CELERY_RESULT_SERIALIZER = 'json',\n",
    "    CELERY_ACCEPT_CONTENT = ['json'],\n",
    "    CELERY_TRACK_STARTED = True,\n",
    "    CELERY_TIMEZONE = 'US/Pacific'\n",
    "    )\n",
    "\n",
    "celery = Celery(CELERY_MAIN, \n",
    "                broker=CELERY_BROKER_URL, \n",
    "                include=['proj.tasks.ascii'])\n",
    "celery.conf.update(CELERY_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the line that includes the tasks in ```proj.tasks.ascii```\n",
    "\n",
    "**To run the worker call:** ```celery -A proj worker -l info```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Celery task\n",
    "Create a task in the project directory.\n",
    "\n",
    "See ```proj/tasks/ascii.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj.tasks.ascii import image_to_ascii_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import helper functions\n",
    "Just ```display_progress_bar_until_completed``` is new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj.helpers import print_ascii_html, display_progress_bar_until_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run the task synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_image_filename = 'samples/images/cat01.jpg'\n",
    "column_count = 200\n",
    "task_result = image_to_ascii_task(cat_image_filename, column_count)\n",
    "ascii_image = task_result.get('result')\n",
    "ascii_image_text = '\\n'.join(line for line in ascii_image)\n",
    "print_ascii_html(ascii_image_text, font_size_pct=30, line_height_pct=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try an asynchronous call\n",
    "\n",
    "* use ```apply_sync``` and ```args``` to queue the task asynchronously\n",
    "* get the results object using AsyncResult(task id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, 400 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_filename = 'samples/images/cat01.jpg'\n",
    "column_count = 400\n",
    "\n",
    "task = image_to_ascii_task.apply_async(args=[image_filename, column_count])\n",
    "task_400 = image_to_ascii_task.AsyncResult(task.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Continue polling the task every 0.5s until the task is complete\n",
    "display_progress_bar_until_completed(task_400)\n",
    "\n",
    "# Then display the results\n",
    "ascii_image = task_400.info.get('result')\n",
    "ascii_image_text = '\\n'.join(line for line in ascii_image)\n",
    "print_ascii_html(ascii_image_text, font_size_pct=30, line_height_pct=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, 800 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_filename = 'samples/images/cat01.jpg'\n",
    "column_count = 800\n",
    "\n",
    "task = image_to_ascii_task.apply_async(args=[image_filename, column_count])\n",
    "task_800 = image_to_ascii_task.AsyncResult(task.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Continue polling the task every 0.5s until the task is complete\n",
    "display_progress_bar_until_completed(task_800)\n",
    "\n",
    "# Then display the results\n",
    "ascii_image = task_800.info.get('result')\n",
    "ascii_image_text = '\\n'.join(line for line in ascii_image)\n",
    "print_ascii_html(ascii_image_text, font_size_pct=15, line_height_pct=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's queue a bunch of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "image_filename = 'samples/images/cat01.jpg'\n",
    "\n",
    "task = image_to_ascii_task.apply_async(args=[image_filename, 100])\n",
    "task_100 = image_to_ascii_task.AsyncResult(task.id)\n",
    "\n",
    "task = image_to_ascii_task.apply_async(args=[image_filename, 200])\n",
    "task_200 = image_to_ascii_task.AsyncResult(task.id)\n",
    "\n",
    "task = image_to_ascii_task.apply_async(args=[image_filename, 400])\n",
    "task_400 = image_to_ascii_task.AsyncResult(task.id)\n",
    "\n",
    "task = image_to_ascii_task.apply_async(args=[image_filename, 800])\n",
    "task_800 = image_to_ascii_task.AsyncResult(task.id)\n",
    "\n",
    "task = image_to_ascii_task.apply_async(args=[image_filename, 1600])\n",
    "task_1600 = image_to_ascii_task.AsyncResult(task.id)\n",
    "\n",
    "display_progress_bar_until_completed(task_100)\n",
    "display_progress_bar_until_completed(task_200)\n",
    "display_progress_bar_until_completed(task_400)\n",
    "display_progress_bar_until_completed(task_800)\n",
    "display_progress_bar_until_completed(task_1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Two immediate benefits here:\n",
    "* First, you can **queue the several tasks** and **continue working** on the same notebook\n",
    "* Second, since I'm running 4 celery workers, the **total run time is much shorter**: 35 versus 45-50s\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Rounds:\n",
    "\n",
    "- [>> Flower](image_conversion_bonus_flower.ipynb)\n",
    "- [>> DynamoDB](image_conversion_bonus_dynamodb.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
